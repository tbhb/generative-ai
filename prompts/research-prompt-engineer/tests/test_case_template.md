# Test Case TC[XXX]: [Test Name]

## Test Classification

- **Test Case ID**: TC[XXX]
- **Test Name**: [Descriptive name for the test scenario]
- **Complexity Level**: [Basic | Intermediate | Advanced]
- **Research Type**: [Literature Review | Market Research | Policy Analysis | Technical Analysis | etc.]
- **Target Models**: [Claude 4 Opus | Claude 4 Sonnet | ChatGPT GPT-4o | ChatGPT o3 | ChatGPT o4-mini | ChatGPT o4-mini-high | Gemini 2.5 Flash | Gemini 2.5 Pro | All | Claude | ChatGPT | Gemini | Specific combinations]
- **Expected Duration**: [Time estimate for full test execution]
- **Evaluation Focus**: [Primary areas to evaluate - e.g., template adherence, file integration, etc.]

## Test Scenario

### User Profile

- **Background**: [User's professional/academic background]
- **Experience Level**: [Novice | Intermediate | Advanced] - [Brief description of AI tool experience]
- **Research Context**: [What the user is working on - thesis, business project, policy brief, etc.]
- **Time Constraints**: [Deadline pressures or time availability]
- **Technical Comfort**: [Level of comfort with AI tools and research methodology]

### Research Request

**Initial User Prompt:**

```markdown
[Include the complete, realistic user prompt that would be submitted to the Research Prompt Engineer. This should be comprehensive enough to minimize socratic questioning while still being realistic for the user profile. Include:

- Clear research topic and objectives
- Specific requirements and constraints
- Timeline and scope expectations
- Format preferences
- Target audience
- Any relevant files or sources
- Platform preferences
- Quality standards expected]
```

**Additional Context** (if needed):

- **Files to Upload**: [List any files that should be included in testing]
- **Follow-up Information**: [Any clarifications the user might provide if asked]
- **Environmental Factors**: [Any external constraints or considerations]

## Expected Outcomes

### Research Problem Development

The Research Prompt Engineer should demonstrate:

- ✅ **Requirement Recognition**: [Specific aspects of requirement capture to evaluate]
- ✅ **Appropriate Questioning**: [What clarifications, if any, should be sought]
- ✅ **Scope Validation**: [How the system should confirm or refine scope]
- ✅ **Model Recommendation**: [Expected guidance on platform selection]
- ✅ **Format Confirmation**: [How output format should be validated]
- ✅ **Success Criteria**: [How the system should establish quality benchmarks]

### Model Recommendations

Should provide expert guidance on:

- **Claude 4 Opus**: [Specific strengths for this research type]
- **Claude 4 Sonnet**: [Specific strengths for this research type]
- **ChatGPT GPT-4o**: [Specific strengths for this research type]
- **ChatGPT o3**: [Specific strengths for this research type]
- **ChatGPT o4-mini**: [Specific strengths for this research type]
- **ChatGPT o4-mini-high**: [Specific strengths for this research type]
- **Gemini 2.5 Flash**: [Specific strengths for this research type]
- **Gemini 2.5 Pro**: [Specific strengths for this research type]
- **Strategic Rationale**: [Why these recommendations are appropriate]

### Generated Prompts Quality

#### Universal Requirements (All Prompts Should Include)

- **Clear Expert Persona**: [Specific expertise the AI should assume]
- **Precise Research Topic**: [Exact focus and boundaries]
- **Scope Definition**: [Temporal, geographic, methodological boundaries]
- **Source Requirements**: [Quality standards and preferred source types]
- **Format Specifications**: [Output structure and style requirements]
- **Quality Assurance**: [Self-critique and verification protocols]
- **Success Metrics**: [How the AI should measure success]

#### Model-Specific Optimizations

**Claude Template Should Feature:**

- [Specific structural elements expected for Claude]
- [XML formatting requirements]
- [Analytical frameworks appropriate for Claude]
- [Self-refinement protocols]

**ChatGPT Template Should Feature:**

- [Specific structural elements expected for ChatGPT]
- [Markdown formatting requirements]
- [Tool orchestration guidance]
- [Quality verification approaches]

**Gemini Template Should Feature:**

- [Specific structural elements expected for Gemini]
- [Interactive planning elements]
- [Structured section requirements]
- [Thinking budget considerations]

### Success Criteria

#### Process Evaluation

- **Workflow Efficiency**: [Specific interaction patterns expected]
- **Requirement Capture**: [Completeness standards]
- **Guidance Quality**: [Appropriateness of recommendations]
- **Confirmation Protocols**: [Validation approaches]

#### Prompt Quality

- **Template Adherence**: [Specific formatting requirements]
- **Placeholder Replacement**: [Accuracy and completeness standards]
- **Instruction Clarity**: [Unambiguous direction criteria]
- **Model Optimization**: [Platform-specific enhancement evidence]
- **Quality Protocols**: [Verification and refinement standards]

#### Research Design

- **Methodological Soundness**: [Appropriate analytical approaches]
- **Scope Appropriateness**: [Realistic and manageable boundaries]
- **Source Standards**: [Quality and credibility requirements]
- **Practical Utility**: [Likelihood of producing valuable results]

### Potential Failure Modes

#### Critical Failures (Automatic Score of 1)

- [Specific conditions that constitute critical failures]
- [Template compliance failures]
- [Instruction clarity failures]
- [Quality assurance omissions]

#### Major Issues (Score of 2)

- [Conditions that represent significant problems]
- [Moderate template deviations]
- [Unclear or confusing instructions]
- [Weak analytical frameworks]

#### Minor Issues (Score of 3)

- [Conditions that represent minor improvement opportunities]
- [Small formatting inconsistencies]
- [Opportunities for clearer guidance]
- [Potential optimization improvements]

### Evaluation Benchmarks

#### Excellent Performance (Score: 5)

- **Template Adherence**: Perfect compliance with all model-specific formatting requirements, complete placeholder replacement, flawless structure
- **Research Methodology**: Sophisticated analytical frameworks, comprehensive source quality protocols, robust quality assurance implementation
- **Prompt Quality**: Crystal-clear instructions, optimal model-specific optimization, complete and actionable guidance
- **Overall**: Production-ready prompts that can be used immediately without any modifications

#### Good Performance (Score: 4)

- **Template Adherence**: Minor formatting inconsistencies or 1-2 placeholder issues, generally proper structure
- **Research Methodology**: Sound analytical approach with small gaps, good source protocols, adequate quality checks
- **Prompt Quality**: Clear instructions with occasional ambiguity, good model optimization, mostly complete guidance
- **Overall**: High-quality prompts needing 1-2 small refinements to reach excellence

#### Satisfactory Performance (Score: 3)

- **Template Adherence**: Some template deviations, several placeholder issues, acceptable but improvable structure
- **Research Methodology**: Basic analytical frameworks, reasonable source standards, minimum quality requirements met
- **Prompt Quality**: Generally clear instructions with some confusion, adequate model optimization, acceptable completeness
- **Overall**: Functional prompts that meet basic requirements but have room for enhancement

#### Needs Improvement (Score: 2)

- **Template Adherence**: Significant formatting problems, multiple placeholder failures, poor structural compliance
- **Research Methodology**: Weak analytical approaches, insufficient source standards, inadequate quality protocols
- **Prompt Quality**: Unclear or confusing instructions, poor model optimization, incomplete guidance
- **Overall**: Substantial work needed before prompts can be effectively used

#### Poor Performance (Score: 1)

- **Template Adherence**: Major formatting failures, widespread placeholder errors, incorrect or missing structure
- **Research Methodology**: Flawed or missing analytical frameworks, no source quality standards, absent quality assurance
- **Prompt Quality**: Incomprehensible instructions, no model optimization, critical information missing
- **Overall**: Fundamental revision required before prompts can function at all

## Test Validation

### Pre-Test Checklist

- [ ] Research Prompt Engineer system configured correctly
- [ ] All required template files accessible and current
- [ ] Test evaluation criteria clearly defined
- [ ] Test prompt ready for execution
- [ ] Evaluation framework prepared
- [ ] [Any test-specific preparation requirements]

### Test Execution Protocol

#### Phase 1: Initial Interaction

- [ ] Submit initial user prompt
- [ ] Document system response and any questions
- [ ] Provide any requested clarifications
- [ ] Record interaction efficiency

#### Phase 2: Prompt Generation

- [ ] Confirm final requirements
- [ ] Request prompt generation
- [ ] Collect all generated prompts
- [ ] Verify completeness

#### Phase 3: Quality Verification

- [ ] Review prompts for template adherence
- [ ] Assess model-specific optimizations
- [ ] Evaluate instruction clarity
- [ ] Check quality assurance protocols

### Post-Test Analysis

- [ ] All target prompts generated successfully
- [ ] Templates properly utilized
- [ ] Quality standards met
- [ ] User requirements addressed
- [ ] Model-specific optimizations present
- [ ] [Any test-specific validation requirements]

### Success Indicators

- [ ] Efficient interaction (< [X] exchanges)
- [ ] Comprehensive requirement capture
- [ ] High-quality prompt generation
- [ ] Appropriate model recommendations
- [ ] Clear, actionable outputs
- [ ] [Any test-specific success criteria]

## Expected Outputs

### Research Prompt Engineer Interaction

**Interaction Elements:**

- Initial assessment and requirement clarification
- Model recommendation discussion
- Format and style confirmation
- Final requirement validation
- Prompt generation and delivery

**Quality Indicators:**

- [Specific patterns that indicate good performance]
- [Warning signs that indicate problems]
- [Efficiency benchmarks]

### Generated Research Prompts

#### Primary Artifacts

1. **[Model 1] Research Prompt**: [Brief description of expected characteristics]
2. **[Model 2] Research Prompt**: [Brief description of expected characteristics]
3. **[Model 3] Research Prompt**: [Brief description of expected characteristics]

#### Quality Verification

**Template Compliance:**

- [Specific template elements to verify]
- [Formatting requirements]
- [Structural completeness]

**Content Quality:**

- [Instruction clarity standards]
- [Research methodology appropriateness]
- [Source quality protocols]

**Model Optimization:**

- [Platform-specific enhancements]
- [Formatting optimizations]
- [Capability utilization]

### Evaluation Metrics

#### Quantitative Measures

- **Template Adherence Score**: [Specific scoring criteria]
- **Research Methodology Score**: [Specific scoring criteria]
- **Prompt Quality Score**: [Specific scoring criteria]
- **Overall Score**: [Average or composite approach]

#### Qualitative Indicators

- **User Experience Quality**: [Interaction smoothness, clarity]
- **Practical Utility**: [Likelihood of producing useful results]
- **Professional Standards**: [Appropriateness for target audience]
- **Innovation**: [Creative or particularly effective approaches]

## Test Case Maintenance

### Review Schedule

- **Monthly**: Review relevance and effectiveness
- **Quarterly**: Update based on system changes
- **Annually**: Comprehensive revision and modernization

### Update Triggers

- **System Changes**: When instructions or templates are modified
- **Performance Issues**: When test consistently shows problems
- **User Feedback**: When real users report related issues
- **Technology Changes**: When AI model capabilities evolve

### Version Control

- **Version**: [Current version number]
- **Last Updated**: [Date of last revision]
- **Change Log**: [Record of significant modifications]
- **Next Review**: [Scheduled review date]

## Notes and Considerations

### Special Testing Requirements

- [Any unique aspects of this test case]
- [Specific technical requirements]
- [Environmental considerations]
- [Integration requirements]

### Known Limitations

- [Any known constraints or limitations]
- [Assumptions made in test design]
- [Potential sources of variation]

### Future Enhancements

- [Planned improvements to the test case]
- [Additional scenarios to consider]
- [Integration with other test cases]

---

**Test Case Status**: [Draft | Review | Approved | Active | Deprecated]
**Created By**: [Author name]
**Created Date**: [Creation date]
**Last Modified**: [Last modification date]
**Review Due**: [Next review date]
